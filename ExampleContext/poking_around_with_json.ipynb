{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"Reddit_MensRights.ndjson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_file) as ndsjon_file:\n",
    "    data  = ndjson.load(ndsjon_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719983"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"it's\", 'also', 'the', 'perfect', 'defense', '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = defaultdict(list)\n",
    "\n",
    "for sentence in data:\n",
    "    words_added = set()\n",
    "    for word in sentence:\n",
    "        if word not in words_added:\n",
    "            vocab[word].append(sentence)\n",
    "            words_added.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(l):\n",
    "    ''' pretty print a list of (word, tag) tuples '''\n",
    "    words = ''\n",
    "    tags  = ''\n",
    "    for word, tag in l:\n",
    "        if tag is None: tag = ''\n",
    "        width = max((len(word), len(tag)))\n",
    "        paddstr = \"{:<\"+ str(width) +\"} \"\n",
    "        \n",
    "        words += paddstr.format(word)\n",
    "        tags  += paddstr.format(tag)\n",
    "    \n",
    "    print(words)\n",
    "    print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(focus_word, other_words=set(), focus_bonus=2, example_length = 11, num_examples=2):\n",
    "    ''' returns the sentence containing the most occurances of focus_word.\n",
    "        if the focus_word does not occur in the corpus, raises a ValueError\n",
    "        if the optional other_words set is provided, returns the sentence\n",
    "        containing the greatest number of other words.\n",
    "        \n",
    "        The 'best' sentence is computed by summing the occurances of other_words with\n",
    "        focus_bonus * the occurances of focus_word\n",
    "        \n",
    "        if the resulting example sentence is longer than example_length, the returned\n",
    "        example will be centered around the focus word and \"clipped\" at length\n",
    "        example_length.\n",
    "        \n",
    "        sentences returned as a list of tuples of (token, None or 'focus' or 'other')\n",
    "    '''\n",
    "    if focus_word not in vocab:\n",
    "        #raise ValueError(\"{} is not in this corpus' vocabulary.\".format(focus_word))\n",
    "        return []\n",
    "        \n",
    "    # make sure example_length is odd\n",
    "    if example_length % 2 == 0: example_length += 1\n",
    "    \n",
    "    possible_sentences = vocab[focus_word]\n",
    "    scored_possible_sentences = []\n",
    "    for sentence in possible_sentences:\n",
    "        score = 0\n",
    "        for word in sentence:\n",
    "            if word == focus_word:\n",
    "                score += focus_bonus\n",
    "            elif word in other_words:\n",
    "                score += 1\n",
    "        scored_possible_sentences.append( (sentence, score) )\n",
    "        \n",
    "    sentences = sorted(scored_possible_sentences, key=lambda x: x[1], reverse=True)\n",
    "    sentences = sentences[:num_examples] if len(sentences)>num_examples else sentences\n",
    "    sentences = map(lambda x: x[0], sentences)    \n",
    "    \n",
    "    def trimmer(sentence):\n",
    "        if len(sentence) > example_length:\n",
    "            pos_of_focus = sentence.index(focus_word)\n",
    "\n",
    "            if pos_of_focus < int(example_length/2):\n",
    "                # focus_word is at front of sentence\n",
    "                sentence = sentence[:example_length]\n",
    "            else:\n",
    "                padding  = int(example_length/2)\n",
    "                front = pos_of_focus - padding\n",
    "                back =  pos_of_focus + padding\n",
    "                sentence = sentence[front:back+1]\n",
    "        return sentence\n",
    "            \n",
    "    def tagger(word):\n",
    "        tag = None\n",
    "        if word == focus_word:    tag = 'focus'\n",
    "        elif word in other_words: tag = 'other'\n",
    "        return (word, tag)\n",
    "    \n",
    "    def sentence_tagger(sentence):\n",
    "        return list(map(tagger, sentence))\n",
    "    \n",
    "    sentences = list(map(trimmer, sentences))\n",
    "    sentences = list(map(sentence_tagger, sentences))\n",
    "    \n",
    "    return sentences\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is it racist for him to sell me a taco  or racist for him to refuse to sell me a taco  ? \n",
      "                                  focus                                          focus   \n",
      "\n",
      "it won't , one knotted condom is nothing compared to a taco  bell meal , but even if it did - no problem , that can be your calling card \n",
      "                                                       focus                                                                             \n",
      "\n",
      "wow , now i'm wondering , if you eat a taco  and you're not a mexican national , are you guilty of cultural food appropriation ? \n",
      "                                       focus                                                                                     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = get_examples('taco', example_length=50, num_examples=3)\n",
    "\n",
    "for sentence in s:\n",
    "    pretty_print(sentence)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = ['a','b','c','d','e','f','g','h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"b\" in set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:codedwords]",
   "language": "python",
   "name": "conda-env-codedwords-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
